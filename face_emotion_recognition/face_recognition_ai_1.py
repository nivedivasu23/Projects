# -*- coding: utf-8 -*-
"""face_recognition_ai 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eKU2JGXLNr3KL-MvZaKVuRC9pP1BYMPt
"""

from google.colab import drive
drive.mount('/content/gdrive')

import numpy as np
import pandas as pd
from keras.models import Sequential
from keras.layers.core import Flatten,Dense,Dropout
from keras.utils.np_utils import to_categorical
from keras.layers.convolutional import Convolution2D , MaxPooling2D ,ZeroPadding2D
from tensorflow.keras.layers import Dense , Conv2D , Flatten , Dropout , MaxPooling2D , Activation
from tensorflow.keras.losses import categorical_crossentropy
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
from tensorflow import keras
from keras.optimizers import SGD
import cv2

data = pd.read_csv('/content/gdrive/MyDrive/fer2013.csv')
print(data.shape)
print(data.head(5))
print(data.tail(5))

data['Usage'].value_counts()

data['emotion'].value_counts()

x_train , train_y , x_test ,test_y = [],[],[],[]

for index, row in data.iterrows():
  val = row['pixels'].split(" ")
  try:
    if 'Training' in row['Usage']:
       x_train.append(np.array(val,'float32'))
       train_y.append(row['emotion'])
    elif 'PublicTest' in row['Usage']:
       x_test.append(np.array(val,'float32'))
       test_y.append(row['emotion'])
  except:
    print(f"error occured at index :{index} and row :{row}")

x_train[0:5]

num_feature = 64
num_labels = 7
batch_size = 64
epochs = 80
width,height = 48,48

X_train = np.array(x_train,'float32')
train_Y = np.array(train_y,'float32')
X_test = np.array(x_test,'float32')
test_Y = np.array(test_y,'float32')

train_Y = to_categorical(train_Y,num_classes=num_labels)
test_Y= to_categorical(test_Y,num_classes=num_labels)
print(X_train.shape)
print(X_test.shape)

X_train -= np.mean(X_train,axis = 0)
X_train /= np.std(X_train,axis = 0)


X_test -= np.mean(X_test,axis = 0)
X_test /= np.std(X_test,axis = 0)

X_train = X_train.reshape(X_train.shape[0],48,48,1)
X_test = X_test.reshape(X_test.shape[0],48,48,1)


print(f"shape{X_train.shape}")

print(f"shape{X_test.shape}")

model = Sequential()
# add 1st layer
model.add(Conv2D(64,kernel_size=(3,3),activation='relu',input_shape=(X_train.shape[1:])))
model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))
model.add(Dropout(0.5))
 
#add 2nd layer
 
model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))
model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))
model.add(Dropout(0.5))
 
# add 3rd layer
model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))
model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))
 
model.add(Flatten())
 
 
model.add(Dense(1024,activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(1024,activation='relu'))
model.add(Dropout(0.2))
 
model.add(Dense(num_labels,activation='softmax'))
 
model.summary()

# compile model

model.compile(loss=categorical_crossentropy,
              optimizer = 'sgd',
              metrics=['accuracy'])

model.fit(X_train,train_Y,
          batch_size= batch_size,
          epochs = epochs,
          verbose = 1,
          validation_data =(X_test,test_Y),
          shuffle= True)

fer_json = model.to_json()
with open('fer.json','w') as json_file:
  json_file.write(fer_json)
model.save_weights('fer.h5')

import cv2
from keras.models import model_from_json

model = model_from_json(open('fer.json','r').read())
model.load_weights('fer.h5')
face_haar_cascade = cv2.CascadeClassifier('/content/gdrive/MyDrive/haarcascade_frontalface_default.xml')

from google.colab.patches import cv2_imshow

test_image = cv2.imread('/content/samp5.jpg')
cv2_imshow(test_image)

gray_img = cv2.cvtColor(test_image,cv2.COLOR_BGR2GRAY)
#cv2_imshow(gray_img)

from keras.preprocessing.image import  img_to_array

faces = face_haar_cascade.detectMultiScale(gray_img,1.1,4)

# draw rectangle around face

for (x,y,w,h) in faces:
  cv2.rectangle(test_image,(x,y),(x+w,y+h),(2500,0,0))
  roi_gray = gray_img[y:y+w,x:x+h]
  roi_gray = cv2.resize(roi_gray,(48,48))
  image_pixels = img_to_array(roi_gray)
  image_pixels = np.expand_dims(image_pixels,axis=0)
  image_pixels /= 255
  prediction = model.predict(image_pixels)
  max_index = np.argmax(prediction[0])
  emotion_detection = ('angry','disgust','fear','happy','sad','surprise','neutral')
  emotion_prediction = emotion_detection[max_index ]
  print(emotion_prediction)
  font = cv2.FONT_HERSHEY_SIMPLEX
  org=(50,50)
  fontscale = 1
  color = (255,0,0)
  thickness = 2
  image = cv2.putText(test_image,emotion_prediction,org,font,
                      fontscale,color,thickness,cv2.LINE_AA)
  cv2_imshow(image)